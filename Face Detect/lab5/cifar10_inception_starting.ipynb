{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wpHziT7hIcg7"
   },
   "source": [
    "## Laborator 4 Versiune Imbunatatita\n",
    "\n",
    "## Obiective\n",
    "\n",
    "* familiaziraze cu tensorflow slim.\n",
    "* modificarea unei retele neurale in slim\n",
    "* vizualizare date input\n",
    "* vizualizare activari\n",
    "* tf.metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dXu-4AmXLcjn"
   },
   "source": [
    "## Pasul 0. Upload dependinte Python#\n",
    "\n",
    "* cifar10.py\n",
    "* download.py\n",
    "* dataset.py\n",
    "* cache.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "srTcnQt9uBGQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RJrs-lx_MPjU"
   },
   "outputs": [],
   "source": [
    "# verificam ca totul este ok\n",
    "!ls ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T5ja2vEKMGyp"
   },
   "source": [
    "## Pasul 1. Incarcarea dataset-ului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yynlRpNIujw_"
   },
   "outputs": [],
   "source": [
    "import cifar10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ru7DT110vXrI"
   },
   "outputs": [],
   "source": [
    "cifar10.maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "O84le8Amu_tl"
   },
   "outputs": [],
   "source": [
    "!ls data/CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nXdp3l8CMdHP"
   },
   "source": [
    "## Pasul 2. Inspecatarea dataset-ului. Histograma + Imagini sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RSPRpBDSxeUk"
   },
   "outputs": [],
   "source": [
    "class_names = cifar10.load_class_names()\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TjodQ6lyxhFG"
   },
   "outputs": [],
   "source": [
    "images_train, cls_train, labels_train = cifar10.load_training_data()\n",
    "images_test, cls_test, labels_test = cifar10.load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kuJpQuqqxjPe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(images_train.shape)\n",
    "print(images_test.shape)\n",
    "\n",
    "# one hot encodings\n",
    "print(labels_train.shape)\n",
    "print(labels_test.shape)\n",
    "\n",
    "# class labels\n",
    "print(cls_train.shape)\n",
    "print(cls_test.shape)\n",
    "\n",
    "\n",
    "print(\"Train count {}\".format(images_train.shape[0]))\n",
    "print(\"Test count {}\".format(images_test.shape[0]))\n",
    "\n",
    "cls_ids = np.unique(cls_train)\n",
    "print(\"Class labels {}.\".format(cls_ids))\n",
    "\n",
    "n_classes = len(cls_ids)\n",
    "print(\"Num classes {}\".format(n_classes))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2I1HjPlIyBbS"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Yxnn8abZNqlm"
   },
   "outputs": [],
   "source": [
    "# check data statistics\n",
    "\n",
    "def get_stats(labels):\n",
    "    stats = np.zeros(n_classes)\n",
    "    for e in labels:\n",
    "        stats[e] += 1\n",
    "    return stats\n",
    "  \n",
    "# bar_width = 0.\n",
    "def plot_stats(stats, title):\n",
    "    plt.figure()\n",
    "    x = range(n_classes)\n",
    "    plt.title(title)\n",
    "    plt.bar(x, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bGkebuIixo8h"
   },
   "outputs": [],
   "source": [
    "y_train = cls_train\n",
    "y_test = cls_test\n",
    "\n",
    "X_train = images_train\n",
    "X_test = images_test\n",
    "\n",
    "train_stats = get_stats(y_train)\n",
    "test_stats = get_stats(y_test)\n",
    "\n",
    "plt.figure()\n",
    "plot_stats(train_stats, \"Training samples/class\")\n",
    "plot_stats(test_stats, \"Testing samples/class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KuT2ljMZx6SK"
   },
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None, smooth=True):\n",
    "\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "\n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "    # Adjust vertical spacing if we need to print ensemble and best-net.\n",
    "    if cls_pred is None:\n",
    "        hspace = 0.3\n",
    "    else:\n",
    "        hspace = 0.6\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Interpolation type.\n",
    "        if smooth:\n",
    "            interpolation = 'spline16'\n",
    "        else:\n",
    "            interpolation = 'nearest'\n",
    "\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i, :, :, :],\n",
    "                  interpolation=interpolation)\n",
    "            \n",
    "        # Name of the true class.\n",
    "        cls_true_name = class_names[cls_true[i]]\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true_name)\n",
    "        else:\n",
    "            # Name of the predicted class.\n",
    "            cls_pred_name = class_names[cls_pred[i]]\n",
    "\n",
    "            xlabel = \"True: {0}\\nPred: {1}\".format(cls_true_name, cls_pred_name)\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6rKo4yGSx7jJ"
   },
   "outputs": [],
   "source": [
    "# Get the first images from the test-set.\n",
    "images = images_test[0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = cls_test[0:9]\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true, smooth=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7t8_rfHMQD_g"
   },
   "source": [
    "### Vizualizati dataset-ul cu sample-uri din fiecare clasa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EP1UApvnOTBe"
   },
   "outputs": [],
   "source": [
    "num_samples = 10\n",
    "\n",
    "image_shape = images_train.shape[1:]\n",
    "\n",
    "img_height, img_width = image_shape[0], image_shape[1]\n",
    "\n",
    "print(\"hxw {}x{}\".format(img_height, img_width))\n",
    "\n",
    "def draw_samples(X, y, y_target, num_cl, colormap = None):\n",
    "    c_ids = np.where(y == y_target)\n",
    "    selected_idx = random.sample(c_ids[0].tolist(), num_samples)\n",
    "    for i, idx in enumerate(selected_idx):\n",
    "        plt.subplot(num_cl, num_samples, (num_samples * y_target) + i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X[idx], colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QRpJJ8A9OXQ1"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# index = random.randint(0, len(X_train))\n",
    "# image = X_train[index].squeeze()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(num_samples, img_width))\n",
    "for c in range(n_classes):\n",
    "    draw_samples(X_train, y_train, c, n_classes)\n",
    "# \n",
    "# plt.imshow(image)\n",
    "# plt.axis('off')\n",
    "# print(y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptJWMdiOPNhp"
   },
   "source": [
    "## Pasul 3. Definirea modelului in TensorFlow\n",
    "\n",
    "### *Nota* Vom folosi tensoflow slim pentru a ne face viata mai usoara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jrCKThG-182E"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "trunc_normal = lambda stddev: tf.truncated_normal_initializer(stddev=stddev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FmjeHX4yP5Sa"
   },
   "source": [
    "\n",
    "## Definirea unui argument scope. \n",
    "\n",
    "Un argument scope furnizeaza parametri default pentru operatiile din slim.\n",
    "Pentru a consulta parametri default, ne putem uita direct in codul sursa:\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L917"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xAVxGR2EhDKV"
   },
   "outputs": [],
   "source": [
    "def cifarnet_arg_scope_bnorm(weight_decay=0.004, is_training=True):\n",
    "  \"\"\"Defines the batch norm cifarnet argument scope.\n",
    "\n",
    "  Args:\n",
    "    weight_decay: The weight decay to use for regularizing the model.\n",
    "\n",
    "  Returns:\n",
    "       An `arg_scope` to use for the cifarnet model.\n",
    "  \"\"\"\n",
    "  \n",
    "  batch_norm_params = {\n",
    "      'is_training': is_training,\n",
    "      'center': True,\n",
    "      'scale': True,\n",
    "      'decay': 0.997,\n",
    "      'epsilon': 0.001,\n",
    "  }\n",
    "  \n",
    "  with slim.arg_scope(\n",
    "      [slim.conv2d],\n",
    "      weights_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "      activation_fn=tf.nn.relu6,\n",
    "      normalizer_fn=slim.batch_norm):\n",
    "    with slim.arg_scope([slim.batch_norm], **batch_norm_params):\n",
    "      with slim.arg_scope(\n",
    "          [slim.fully_connected],\n",
    "          biases_initializer=tf.constant_initializer(0.1),\n",
    "          weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "          weights_regularizer=slim.l2_regularizer(weight_decay),\n",
    "\n",
    "          activation_fn=tf.nn.relu) as sc:\n",
    "         \n",
    "          return sc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8-TnZPwpSVlv"
   },
   "source": [
    "## CifarNet Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Otg1lZmIxVtV"
   },
   "outputs": [],
   "source": [
    "def inception_module(net, maps, scope=None, reuse=None):\n",
    "  conv_1x1_map = maps[0]   # număr feature maps branch 1\n",
    "  reduce_3x3_map = maps[1] # număr feature maps reduction branch 2\n",
    "  reduce_5x5_map = maps[2] # număr feature maps reduction branch 3\n",
    "  conv_3x3_map = maps[3]   # număr feature maps branch 2\n",
    "  conv_5x5_map = maps[4]   # număr feature maps branch 3\n",
    "  conv_1x1_4_map = maps[5] # număr feature maps branch 4\n",
    "  \n",
    "  ###################################\n",
    "  #         Your code here          #\n",
    "  ###################################\n",
    "  \n",
    "  return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "oOKURdnR1HKy"
   },
   "outputs": [],
   "source": [
    "trunc_normal = lambda stddev: tf.truncated_normal_initializer(stddev=stddev)\n",
    "\n",
    "def cifarnet_bn(images, num_classes=10, is_training=False,\n",
    "             dropout_keep_prob=0.5,\n",
    "             prediction_fn=slim.softmax,\n",
    "             scope='CifarNet'):\n",
    " \n",
    "  end_points = {}\n",
    "\n",
    "  with tf.variable_scope(scope, 'CifarNet', [images]):\n",
    "  ###################################\n",
    "  #         Your code here          #\n",
    "  ###################################\n",
    "\n",
    "  return logits, end_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "r4Be5RPN3vji"
   },
   "outputs": [],
   "source": [
    "# parametri de training si input\n",
    "batch_size = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "num_classes = 10\n",
    "initial_learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4VvaEQ1xJnBx"
   },
   "source": [
    "### Adaugarea conexiunilor de intrare. tf.placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "K_UnNVVv3qCT"
   },
   "outputs": [],
   "source": [
    "    def add_preprocessing(image_input, is_training):\n",
    "      \n",
    "        def _process_image(augment_level, image):\n",
    "            # Because these operations are not commutative, consider randomizing\n",
    "            # randomize the order their operation.\n",
    "            if augment_level > 0:\n",
    "                image = tf.image.random_brightness(image, max_delta=30)\n",
    "                image = tf.image.random_contrast(image, lower=0.75, upper=1.25)\n",
    "            if augment_level > 1:\n",
    "                image = tf.image.random_saturation(image, lower=0.5, upper=1.6)\n",
    "                image = tf.image.random_hue(image, max_delta=0.15)\n",
    "            image = tf.minimum(image, 255.0)\n",
    "            image = tf.maximum(image, 0)\n",
    "            return image\n",
    "\n",
    "        def _preprocess_train(input_tensor):\n",
    "            input_tensor = tf.image.random_flip_left_right(input_tensor)\n",
    "            input_tensor = tf.subtract(input_tensor, 0.5)\n",
    "            input_tensor = tf.multiply(input_tensor, 2.0)\n",
    "\n",
    "            return input_tensor\n",
    "          \n",
    "        def _preprocess_test(input_tensor):\n",
    "            input_tensor = tf.subtract(input_tensor, 0.5)\n",
    "            input_tensor = tf.multiply(input_tensor, 2.0)\n",
    "            \n",
    "            return input_tensor\n",
    "          \n",
    "        preprocessed_input = tf.map_fn(lambda img:\n",
    "                                 tf.cond(\n",
    "                                   tf.equal(\n",
    "                                        is_training,\n",
    "                                     tf.constant(True)),\n",
    "                                    lambda: _preprocess_train(img),\n",
    "                                    lambda: _preprocess_test(img)), image_input)\n",
    "\n",
    "        return preprocessed_input\n",
    "          \n",
    "        \n",
    "    def add_placeholders():\n",
    "        \n",
    "        # image batch input\n",
    "        image_input = tf.placeholder(\n",
    "            tf.float32, [None, height, width, 3],\n",
    "            name='image_input'\n",
    "        )\n",
    "\n",
    "        label_input = tf.placeholder(\n",
    "            tf.int64, [None],\n",
    "            name='label_input'\n",
    "        )\n",
    "        \n",
    "        is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "        \n",
    "        learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "        \n",
    "        return image_input, label_input, is_training, learning_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XHBdKzBx28d"
   },
   "source": [
    "### Nota\n",
    "Pentru augmentare adaugati o operatie tensorflow in input:\n",
    "\n",
    "```\n",
    "\n",
    "if is_training:\n",
    "    scaled_input_tensor = tf.scalar_mul((1.0 / 255), _process_image(1, image_input))\n",
    "else:\n",
    "    scaled_input_tensor = tf.scalar_mul((1.0 / 255), self.image_input)\n",
    "\n",
    "scaled_input_tensor = tf.subtract(scaled_input_tensor, 0.5)\n",
    "self.scaled_input_tensor = tf.multiply(scaled_input_tensor, 2.0)\n",
    "\n",
    "```\n",
    "\n",
    "Mai sus se opereaza folosind `_process_image` augmenatere de brgithnes si saturation.\n",
    "Inainte, input-ul este normalizat.\n",
    "\n",
    "Normalizarea se efectueaza atat la training cat si la testing.\n",
    "Augmentarea se efectueaza doar la testing si are rol in generelizare.\n",
    "\n",
    "Puteti folosi si horizontal flipping `tf.image.random_flip_left_right`\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/image/random_flip_left_right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "x_q1yGSB7s1A"
   },
   "outputs": [],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "21vqUW0c_X2g"
   },
   "outputs": [],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TT3OpO89_5UW"
   },
   "outputs": [],
   "source": [
    "np.unique(cls_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yDMGR4tDJ2Dw"
   },
   "source": [
    "### Functie helper pentru a incarca un minibatch random la training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LMtvX9xwASl8"
   },
   "outputs": [],
   "source": [
    "def random_batch(img, labels, bsize=32):\n",
    "    # Number of images in the training-set.\n",
    "    num_images = len(img)\n",
    "    #     print(num_images)\n",
    "\n",
    "    # Create a random index.\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=bsize,\n",
    "                           replace=False)\n",
    "\n",
    "    # Use the random index to select random images and labels.\n",
    "    x_batch = img[idx, :, :, :]\n",
    "    y_batch = labels[idx]\n",
    "\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kicRVSn9AWzZ"
   },
   "outputs": [],
   "source": [
    "x, y = random_batch(X_train, y_train)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C-sZgA4aKSIU"
   },
   "source": [
    "### Functie helper pentru obtinirea unui batch la test. Nu facem shuffle la test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "H68HVlnossrZ"
   },
   "outputs": [],
   "source": [
    "def get_batch(imgs, labels, step, bsize=32):\n",
    "  offset = (step * batch_size) % (labels.shape[0] - batch_size)\n",
    "#   print(offset)\n",
    "  batch_imgs = imgs[offset:(offset + bsize), :, :, :]\n",
    "  batch_labels = labels[offset:(offset + bsize)]\n",
    "  \n",
    "  return batch_imgs, batch_labels\n",
    "  \n",
    "batch_imgs, batch_labels = get_batch(images_test, cls_test, 2)\n",
    "  \n",
    "print(batch_imgs.shape)\n",
    "print(batch_labels.shape)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1RPubRTLKc0k"
   },
   "source": [
    "### Functie pentru evaluare acuratete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YA_L36h0ay7X"
   },
   "outputs": [],
   "source": [
    "#evaluate model\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "  bsize = 32\n",
    "  total_examples = cls_test.shape[0]  \n",
    "  iters = int(total_examples/bsize)\n",
    "  \n",
    "  acc = []\n",
    "  losses = []\n",
    "    \n",
    "  for i in range(iters):\n",
    "    \n",
    "    x, y = get_batch(images_test, cls_test, i, bsize)\n",
    "\n",
    "    feed_dict = {\n",
    "\n",
    "        image_input: x,\n",
    "        label_input: y,\n",
    "        is_training: False\n",
    "\n",
    "    }\n",
    "\n",
    "    testAcc, testLoss = sess.run([accuracy, loss], feed_dict=feed_dict)\n",
    "    acc.append(testAcc)\n",
    "    losses.append(testLoss)\n",
    "    \n",
    "  meanAcc = np.mean(np.asarray(acc))\n",
    "  meanLoss = np.mean(np.asarray(losses))\n",
    "  \n",
    "  return meanAcc, meanLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "t094SL0wKuuT"
   },
   "outputs": [],
   "source": [
    "trainingAccuracyList = []\n",
    "trainingLossList = []\n",
    "testAccuracyList = []\n",
    "testLossList = []\n",
    "learningRateList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-UUqX-AVCeWF"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "g = tf.Graph().as_default()\n",
    "image_input, label_input, is_training, learning_rate = add_placeholders()\n",
    "preprocessed_image_input = add_preprocessing(image_input, is_training)\n",
    "\n",
    "\n",
    "arg_scope = cifarnet_arg_scope_bnorm(is_training=is_training)\n",
    "with slim.arg_scope(arg_scope):\n",
    "  logits, end_points = cifarnet_bn(preprocessed_image_input, is_training=is_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ub2tDVS-KAJo"
   },
   "source": [
    "### Definirea pasilor de antrenare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JAMeODSj_w4P"
   },
   "outputs": [],
   "source": [
    "initial_learning_rate = 1e-3\n",
    "num_steps = int(50000)\n",
    "num_examples = images_train.shape[0]\n",
    "iters = num_examples / batch_size\n",
    "learning_rate_step = 10000\n",
    "learning_rate_decay = 0.5\n",
    "\n",
    "\n",
    "\n",
    "loss = tf.reduce_mean(\n",
    "  tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label_input, logits=logits))\n",
    "\n",
    "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
    "predictions = end_points['Predictions']\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(predictions, 1), label_input)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Optimizer.\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# for batch norm training. Note: we should use slim.train_op\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "  # Ensures that we execute the update_ops before performing the train_step\n",
    "#   optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "  optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "# actually initialize our variables\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "  \n",
    "running_lr = initial_learning_rate\n",
    "\n",
    "print(\"Starting optimization\")\n",
    "print(\"Batch size {}\".format(batch_size))\n",
    "print(\"Initial LR {}. LR stepdown itnerval {}. LR deacy factor {}\".format(running_lr, learning_rate_step, learning_rate_decay))\n",
    "\n",
    "for i in range(num_steps):\n",
    "  x, y = random_batch(X_train, y_train, bsize=batch_size)\n",
    "\n",
    "  feed_dict = {\n",
    "\n",
    "      image_input: x,\n",
    "      label_input: y,\n",
    "      is_training: True,\n",
    "      learning_rate : running_lr\n",
    "\n",
    "  }\n",
    "\n",
    "  if i % 200 == 0:\n",
    "      _, trainAcc, trainLoss = sess.run([optimizer, accuracy, loss], feed_dict=feed_dict)\n",
    "      \n",
    "      testAcc, testLoss = evaluate()\n",
    "      \n",
    "      print(\"Train \" + str(i) + \": accuracy:\" + str(trainAcc) + \" loss: \" + str(trainLoss))\n",
    "      print(\"Test \" + str(i) + \": accuracy:\" + str(testAcc) + \" loss: \" + str(testLoss))\n",
    "      \n",
    "      trainingAccuracyList.append(trainAcc)\n",
    "      trainingLossList.append(trainLoss)\n",
    "      testAccuracyList.append(testAcc)\n",
    "      testLossList.append(testLoss)\n",
    "      learningRateList.append(running_lr)\n",
    "     \n",
    "  else:\n",
    "      sess.run([optimizer], feed_dict=feed_dict)\n",
    "  \n",
    "  \n",
    "  if  i > 0 and i % learning_rate_step == 0:\n",
    "      print(\"Learning reate step down. Old {}. New {}\".format(running_lr, running_lr * learning_rate_decay))\n",
    "      running_lr = running_lr * learning_rate_decay\n",
    "      \n",
    "          \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rsU44I5hNZSn"
   },
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "UM0RCLM8J-oG"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1,2,1);\n",
    "plt.plot(trainingAccuracyList, label=\"Train Acc\");\n",
    "plt.plot(testAccuracyList, label=\"Test Acc\");\n",
    "plt.title(\"Accuracy\");\n",
    "plt.legend();\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1,2,2);\n",
    "plt.plot(trainingLossList, label=\"Train Loss\");\n",
    "plt.plot(testLossList, label=\"Test Loss\");\n",
    "plt.title(\"Loss\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5BZ-S8HBNmqg"
   },
   "source": [
    "## Evaluate final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uGpA40fHad1I"
   },
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "acc, test_loss = evaluate()\n",
    "\n",
    "print(\"Test accuracy:\" + str(acc) + \" loss: \" + str(test_loss))\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4HywbF3QoBc"
   },
   "source": [
    "## Save a model checkpoint. Restoring a model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "R2AtYb0uqkYO"
   },
   "outputs": [],
   "source": [
    "# Save / restore model\n",
    "\n",
    "#!mkdir ckpts\n",
    "\n",
    "vars_to_save = tf.global_variables()\n",
    "saver = tf.train.Saver(var_list=vars_to_save)\n",
    "\n",
    "\n",
    "model_name ='./ckpts/cifarnet-batchnorm.ckpt'\n",
    "saver.save(sess, model_name, global_step=num_steps)\n",
    "print(vars_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1qvG9566ju9o"
   },
   "source": [
    "## Exmplu calcul acuratete folosint tf.metrics\n",
    "\n",
    "`tf.metrics.accuracy` \n",
    "\n",
    "```\n",
    "labels = ...\n",
    "predictions = ...\n",
    "accuracy, update_op_acc = tf.metrics.accuracy(\n",
    "    labels, predictions)\n",
    "error, update_op_error = tf.metrics.mean_absolute_error(\n",
    "    labels, predictions)\n",
    "\n",
    "sess.run(tf.local_variables_initializer())\n",
    "for batch in range(num_batches):\n",
    "  sess.run([update_op_acc, update_op_error])\n",
    "\n",
    "accuracy, mean_absolute_error = sess.run([accuracy, mean_absolute_error])\n",
    "\n",
    "```\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "071zo-MuRBI4"
   },
   "source": [
    "## Testing model restore works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XvHmyUcgueaw"
   },
   "outputs": [],
   "source": [
    "# test restore works\n",
    "evaluate()\n",
    "sess.run(init)\n",
    "evaluate()\n",
    "vars_to_restore = tf.global_variables()\n",
    "saver = tf.train.Saver(var_list=vars_to_restore)\n",
    "model_to_restore = \"{}-{}\".format(model_name, num_steps)\n",
    "saver.restore(sess, model_to_restore)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Y7JLKSjOsQFq"
   },
   "outputs": [],
   "source": [
    "#!ls ./ckpts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qHqvhEvxSCQo"
   },
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cr87Erqjmnge"
   },
   "outputs": [],
   "source": [
    "x, y = get_batch(images_test, cls_test, i)\n",
    "\n",
    "y = y[:4]\n",
    "print(y)\n",
    "print(num_classes)\n",
    "\n",
    "res = tf.one_hot(indices=y, depth=num_classes)\n",
    "print(sess.run(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2CkNbf7HSI8p"
   },
   "source": [
    "### Masurarea performantelor retelei folosind tf.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6smOZanJj2q_"
   },
   "outputs": [],
   "source": [
    "# Remember\n",
    "\n",
    "# predictions = end_points['Predictions']\n",
    "# correct_prediction = tf.equal(tf.argmax(predictions, 1), label_input)\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# adaugam on nod pentru one hot\n",
    "\n",
    "labels = tf.one_hot(indices=label_input, depth=num_classes)\n",
    "# accuracy_streamed, update_op_acc = tf.contrib.metrics.streaming_accuracy(label_input, tf.argmax(predictions, 1))\n",
    "\n",
    "accuracy_streamed, update_op_acc = tf.metrics.accuracy(label_input, tf.argmax(predictions, 1))\n",
    "\n",
    "# init = tf.global_variables_initializer()\n",
    "sess.run(tf.local_variables_initializer())\n",
    "  \n",
    "\n",
    "vars_to_restore = tf.global_variables()\n",
    "saver = tf.train.Saver(var_list=vars_to_restore)\n",
    "saver.restore(sess, model_to_restore)\n",
    "\n",
    "evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vKZ7te-wnfDJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def evaluate_streaming():\n",
    "  total_examples = cls_test.shape[0]\n",
    "  num_batches = int(total_examples / batch_size)\n",
    "  print(\"Total examples {}\".format(total_examples))\n",
    "  print(\"Total iters {}\".format(num_batches))\n",
    "  \n",
    "  for i in range(num_batches):\n",
    "    \n",
    "    x, y = get_batch(images_test, cls_test, i)\n",
    "\n",
    "    feed_dict = {\n",
    "\n",
    "        image_input: x,\n",
    "        label_input: y,\n",
    "        is_training: False\n",
    "\n",
    "    }\n",
    "\n",
    "    #testAcc, testLoss = sess.run([accuracy, loss], feed_dict=feed_dict)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "      _, test_acc = sess.run([update_op_acc, accuracy_streamed],  feed_dict=feed_dict)\n",
    "      print(\"Test \" + str(i) + \": accuracy:\" + str(test_acc))\n",
    "    \n",
    "    else:\n",
    "      sess.run([update_op_acc], feed_dict=feed_dict)\n",
    "    \n",
    "      \n",
    "  test_acc = sess.run(accuracy_streamed)\n",
    "  print(\"Mean Accuracy  {:.2f} %\".format(test_acc * 100))\n",
    "  \n",
    "  \n",
    "evaluate_streaming()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o60ql2sJ1KDO"
   },
   "source": [
    "## Variabile locale vs Variabile globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4oCvIEKAxnnO"
   },
   "outputs": [],
   "source": [
    "tf.local_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yYmseDp9xry3"
   },
   "outputs": [],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZppprM7dbSGR"
   },
   "outputs": [],
   "source": [
    "!ls ckpts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JJRbLRU81XHN"
   },
   "source": [
    "# Vizualizarea Activarilor din retea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JVxaAyapZh0G"
   },
   "outputs": [],
   "source": [
    "# visualize endpoints\n",
    "end_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "UnLJw-ndcVqU"
   },
   "outputs": [],
   "source": [
    "def plotActivations(units):\n",
    "    filters = units.shape[3]\n",
    "    plt.figure(1, figsize=(20,20))\n",
    "    n_columns = 6\n",
    "    n_rows = math.ceil(filters / n_columns) + 1\n",
    "    for i in range(filters):\n",
    "        plt.subplot(n_rows, n_columns, i+1)\n",
    "        plt.title('Filter ' + str(i))\n",
    "        ax = plt.gca()\n",
    "        ax.grid(False)\n",
    "        plt.imshow(units[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9QXVN9eoblQo"
   },
   "outputs": [],
   "source": [
    "conv1 = end_points['conv1']\n",
    "\n",
    "x, y = random_batch(X_train, y_train)\n",
    "\n",
    "feed_dict = {\n",
    "\n",
    "      image_input: x,\n",
    "      label_input: y,\n",
    "      is_training: False\n",
    "\n",
    "  }\n",
    "\n",
    "conv1_fmaps = sess.run(conv1, feed_dict=feed_dict)\n",
    "conv1_fmaps.shape\n",
    "activ1 = conv1_fmaps[0, :, :, :]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3mAKKqm9dW8i"
   },
   "outputs": [],
   "source": [
    "plotActivations(conv1_fmaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7vmg1JnhhrT5"
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Implementați modulul inception din Fig. 1 în cadrul metodei `inception_module`.\n",
    "\n",
    "2. Implementați arhitectura din Fig.2 în cadrul metodei `cifarnet_bn`. (** Atenție la dimensiunea inputului rețelei ** )\n",
    "  * Ar trebui să obțineți 88% accuracy\n",
    "\n",
    "### Bonus\n",
    "\n",
    "1. Combinați arhitectura de mai sus (Inception) cu conexiunile reziduale (ResNet)\n",
    "  * Hint: [Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning](https://arxiv.org/pdf/1602.07261.pdf)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "cifar10_starting_new.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
