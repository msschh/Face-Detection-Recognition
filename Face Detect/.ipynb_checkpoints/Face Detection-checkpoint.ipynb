{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/Programs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACE_PATH = \"/home/alex/Desktop/Face Detection/Face Detect/Positive/\"\n",
    "NON_FACE_PATH = \"/home/alex/Desktop/Face Detection/Face Detect/Negative/\"\n",
    "IN_SIZE = (32,32)   #Input dimensions of image for the network\n",
    "SNAP_COUNT = 5      #Number of random snapshots per non-face image\n",
    "MIN_LEN = 10        #Minimum length for the random snaphsots of non-faces\n",
    "GOOD = [1,0]\n",
    "BAD = [0,1]\n",
    "\n",
    "FACE_COUNT = 30000\n",
    "TRAIN_SPLIT = int(0.7*FACE_COUNT)\n",
    "\n",
    "SAVE_PATH = \"/home/alex/Desktop/Face-Detection-Recognition/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to generate multiple snapshots from an image\n",
    "def rand_snap(img):\n",
    "    r = []\n",
    "    x = img.shape[0]\n",
    "    y = img.shape[1]\n",
    "    #Generate 5 snapshots of different sizes\n",
    "    for i in range(SNAP_COUNT):\n",
    "        snap_size = max([MIN_LEN,int(random.random()*200)])\n",
    "        fx = int(random.random()*(x-snap_size))\n",
    "        fy = int(random.random()*(y-snap_size))\n",
    "        snap = img[fx:fx+snap_size,fy:fy+snap_size]\n",
    "        r.append(cv2.resize(snap,IN_SIZE))\n",
    "    return r\n",
    "\n",
    "#Load the dataset for face/non face classification\n",
    "def load_find_ds():\n",
    "    ds = []\n",
    "    #Load faces (positive samples)\n",
    "    for n in os.listdir(FACE_PATH):\n",
    "        name = FACE_PATH+n\n",
    "        for img_path in os.listdir(name):\n",
    "            t_img = cv2.resize(cv2.imread(name+\"/\"+img_path,0),IN_SIZE)\n",
    "            ds.append((t_img, GOOD))\n",
    "            ds.append((cv2.flip(t_img,1),GOOD)) #Use the horizontal mirror image\n",
    "    random.shuffle(ds)\n",
    "    ds = ds[:FACE_COUNT] \n",
    "    #Load non-faces (negative samples) from dataset\n",
    "    nface_ds = []\n",
    "    for n in os.listdir(NON_FACE_PATH):\n",
    "        name = NON_FACE_PATH+n\n",
    "        for img_path in os.listdir(name):\n",
    "            t_img = cv2.imread(name+\"/\"+img_path,0)\n",
    "            nface_ds.extend([(r,BAD) for r in rand_snap(t_img)])\n",
    "            nface_ds.append((cv2.resize(t_img, IN_SIZE),BAD))\n",
    "    random.shuffle(nface_ds)\n",
    "    nface_ds = nface_ds[:FACE_COUNT]\n",
    "\n",
    "    #Make the train, val and test sets: Ensure 50% for each set\n",
    "    train = ds[:TRAIN_SPLIT]\n",
    "    train.extend(nface_ds[:TRAIN_SPLIT])\n",
    "    random.shuffle(train)\n",
    "    test = ds[TRAIN_SPLIT:]\n",
    "    test.extend(nface_ds[TRAIN_SPLIT:])\n",
    "    random.shuffle(test)\n",
    "\n",
    "    trainX,trainY = map(np.array,zip(*train))\n",
    "    testX,testY = map(np.array,zip(*test))\n",
    "\n",
    "    return ((trainX,trainY),(testX,testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "((trainX,trainY),(testX,testY)) = load_find_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 32, 32)\n",
      "(18000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30000, 30000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(trainY)+sum(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the net in the session\n",
    "def build_net(sess):\n",
    "    in_len = 32\n",
    "    in_dep = 1\n",
    "\n",
    "    x_hold = tf.placeholder(tf.float32,shape=[None,in_dep*in_len*in_len])\n",
    "    y_hold = tf.placeholder(tf.float32,shape=[None,2])\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    xt = tf.reshape(x_hold,[-1,in_len,in_len,in_dep])\n",
    "\n",
    "    xt = tf.layers.batch_normalization(xt)\n",
    "    \n",
    "    #Layer 1 - 3x3 convolution\n",
    "    w1 = tf.Variable(tf.truncated_normal([3,3,in_dep,4], stddev=0.1))\n",
    "    b1 = tf.Variable(tf.constant(0.1, shape=[4]))\n",
    "    c1 = nn.relu(nn.conv2d(xt,w1,strides=[1,2,2,1],padding='VALID')+b1)\n",
    "    o1 = nn.max_pool(c1, [1,2,2,1], [1,2,2,1], padding='VALID')\n",
    "    #o1 = tf.layers.batch_normalization(o1)\n",
    "    \n",
    "    print(\"o1 shape: {}\".format(o1.shape))\n",
    "    \n",
    "    #Layer 2 - 3x3 convolution\n",
    "    w2 = tf.Variable(tf.truncated_normal([3,3,4,16], stddev=0.1))\n",
    "    b2 = tf.Variable(tf.constant(0.1, shape=[16]))\n",
    "    c2 = nn.relu(nn.conv2d(o1,w2,strides=[1,2,2,1],padding='VALID')+b2)\n",
    "    o2 = c2\n",
    "    print(\"o2 shape: {}\".format(o2.shape))\n",
    "    \n",
    "    #o3 = o2\n",
    "    \n",
    "    #Layer 3 - 3x3 convolution\n",
    "    w3 = tf.Variable(tf.truncated_normal([3,3,16,32], stddev=0.1))\n",
    "    b3 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "    c3 = nn.relu(nn.conv2d(o2,w3,strides=[1,1,1,1],padding='VALID')+b3)\n",
    "    o3 = o2\n",
    " \n",
    "    print(\"o3 shape: {}\".format(o3.shape))\n",
    "    \n",
    "    \n",
    "    dim = 9*4*4\n",
    "        \n",
    "    #Fully connected layer - 600 units\n",
    "    of = tf.reshape(o3,[-1,dim])\n",
    "    w4 = tf.Variable(tf.truncated_normal([dim,600], stddev=0.1))\n",
    "    b4 = tf.Variable(tf.constant(0.1, shape=[600]))\n",
    "    o4 = nn.relu(tf.matmul(of,w4)+b4)\n",
    "\n",
    "    o4 = nn.dropout(o4, keep_prob)\n",
    "\n",
    "    print(\"o4 shape: {}\".format(o4.shape))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Output softmax layer - 2 units\n",
    "    w5 = tf.Variable(tf.truncated_normal([600,2], stddev=0.1))\n",
    "    b5 = tf.Variable(tf.constant(0.1, shape=[2]))\n",
    "    y = nn.softmax(tf.matmul(o4,w5)+b5)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    return y,x_hold,y_hold,keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds the product of a dimension tuple to find the total legth\n",
    "def dim_prod(dim_arr):\n",
    "    return np.prod([d for d in dim_arr if d != None])\n",
    "\n",
    "#Split to mini batches\n",
    "def batchify(X, Y, batch_size):\n",
    "    batches = [(X[i:i+batch_size],Y[i:i+batch_size]) for i in range(0,X.shape[0],batch_size)]\n",
    "    random.shuffle(batches)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start a TensorFlow session\n",
    "def start_sess():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allocator_type = 'BFC'\n",
    "    sess = tf.Session(config=config)\n",
    "    return sess\n",
    "\n",
    "#Train the model\n",
    "def ftrain(sess, y, x_hold, y_hold, keep_prob, X, Y, testX, testY, lrate=0.5, epsilon=1e-8, n_epoch=100, batch_size=10, print_epoch=100, save_path=None, plot_acc=None):\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_hold*tf.log(y+1e-10), reduction_indices=[1]))\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_hold,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    acc_X = []\n",
    "    acc_Y = []\n",
    "    \n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=lrate,epsilon=epsilon).minimize(cross_entropy)\n",
    "    \n",
    "    #Flatten the input images for the placeholder\n",
    "    flat_len = dim_prod(x_hold._shape_as_list())\n",
    "    X = X.reshape((X.shape[0],flat_len))\n",
    "\n",
    "    print('Starting training session...')\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batch_num = 0\n",
    "    batches = batchify(X,Y,batch_size)\n",
    "    print('Number of batches:',len(batches))\n",
    "    for i in range(n_epoch):\n",
    "        avg_acc = 0\n",
    "        random.shuffle(batches)\n",
    "        for batchX,batchY in batches:\n",
    "            train_accuracy = accuracy.eval(session=sess, feed_dict={x_hold:batchX, y_hold:batchY, keep_prob:1})\n",
    "            avg_acc = avg_acc + train_accuracy\n",
    "            train_step.run(session=sess,feed_dict={x_hold:batchX, y_hold:batchY, keep_prob:0.75})\n",
    "            #print('Epoch '+': '+str(train_accuracy))\n",
    "        print('Epoch '+str(i)+': '+str(avg_acc/len(batches)))\n",
    "\n",
    "        if (not testX is None) & (not testY is None):\n",
    "            testX = testX.reshape((testX.shape[0],flat_len))\n",
    "            test_accuracy = accuracy.eval(session=sess,feed_dict={x_hold:testX, y_hold:testY, keep_prob:1})\n",
    "            #print('Acc test: ',test_accuracy)\n",
    "            if plot_acc is not None:\n",
    "                acc_Y.append(test_accuracy)\n",
    "                acc_X.append(i)\n",
    "\n",
    "    if not save_path is None:\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, \"/home/alex/Desktop/Face Detection/Face Detect/test_model/tm\", global_step=1000)\n",
    "        #merged = tf.summary.merge_all()\n",
    "        #writer = tf.train.SummaryWriter(save_path+'_graph',sess.graph)\n",
    "        #writer.flush()\n",
    "        #writer.close()\n",
    "        print('Model saved')\n",
    "        \n",
    "    if plot_acc is not None:\n",
    "        plt.plot(acc_X, acc_Y, 'r')\n",
    "        plt.show()\n",
    "        \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to run the training\n",
    "def train_net():\n",
    "    train,test = load_find_ds()\n",
    "    sess = start_sess()\n",
    "    y,x_hold,y_hold,keep_prob = build_net(sess)\n",
    "    acc = ftrain(sess,\n",
    "                y,\n",
    "                x_hold,\n",
    "                y_hold,\n",
    "                keep_prob,\n",
    "                train[0],train[1],\n",
    "                test[0],test[1],\n",
    "                lrate=1e-4,\n",
    "                epsilon=1e-16,\n",
    "                n_epoch=50,\n",
    "                batch_size=100,\n",
    "                print_epoch=1,\n",
    "                save_path=True,\n",
    "                plot_acc=True)\n",
    "    print(\"Accuracy:\",acc)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o1 shape: (?, 7, 7, 4)\n",
      "o2 shape: (?, 3, 3, 16)\n",
      "o3 shape: (?, 3, 3, 16)\n",
      "o4 shape: (?, 600)\n",
      "Starting training session...\n",
      "Number of batches: 420\n",
      "Epoch 0: 0.8599285731712977\n",
      "Epoch 1: 0.927261906010764\n",
      "Epoch 2: 0.9476904791025889\n",
      "Epoch 3: 0.966333339044026\n",
      "Epoch 4: 0.9750952468031928\n",
      "Epoch 5: 0.9788571536540985\n",
      "Epoch 6: 0.9819047730593454\n",
      "Epoch 7: 0.9835476307641893\n",
      "Epoch 8: 0.9858333441473189\n",
      "Epoch 9: 0.987476200007257\n",
      "Epoch 10: 0.9885000092642647\n",
      "Epoch 11: 0.9895000090201695\n",
      "Epoch 12: 0.990785722221647\n",
      "Epoch 13: 0.9915238168977556\n",
      "Epoch 14: 0.9922142928554898\n",
      "Epoch 15: 0.9929285778885796\n",
      "Epoch 16: 0.9940476245823361\n",
      "Epoch 17: 0.9940714339415232\n",
      "Epoch 18: 0.994857147477922\n",
      "Epoch 19: 0.9952142902782986\n",
      "Epoch 20: 0.9956904801584425\n",
      "Epoch 21: 0.9955714327948434\n",
      "Epoch 22: 0.9962380988257272\n",
      "Epoch 23: 0.9964761938367571\n",
      "Epoch 24: 0.997071431364332\n",
      "Epoch 25: 0.9972619073731559\n",
      "Epoch 26: 0.9977857163974218\n",
      "Epoch 27: 0.9980476209095546\n",
      "Epoch 28: 0.9975238118852888\n",
      "Epoch 29: 0.9978333353996277\n",
      "Epoch 30: 0.9984523824283055\n",
      "Epoch 31: 0.9984285729272026\n",
      "Epoch 32: 0.9984761919294085\n",
      "Epoch 33: 0.9986428584371294\n",
      "Epoch 34: 0.9989047629492623\n",
      "Epoch 35: 0.9987619059426444\n",
      "Epoch 36: 0.9988809534481593\n",
      "Epoch 37: 0.9990238104547773\n",
      "Epoch 38: 0.9989523819514683\n",
      "Epoch 39: 0.9992142864636012\n",
      "Epoch 40: 0.9991190484591893\n",
      "Epoch 41: 0.9990952389580863\n",
      "Epoch 42: 0.9992619054658073\n",
      "Epoch 43: 0.9994523814746312\n",
      "Epoch 44: 0.9995476194790431\n",
      "Epoch 45: 0.9992142864636012\n",
      "Epoch 46: 0.9996666669845581\n",
      "Epoch 47: 0.9995714289801462\n",
      "Epoch 48: 0.9995000004768372\n",
      "Epoch 49: 0.999714285986764\n",
      "Model saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f448c311780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9921111\n"
     ]
    }
   ],
   "source": [
    "train_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
